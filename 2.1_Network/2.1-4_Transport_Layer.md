# 2.1-4 Transport Layer

> Active Recall
> 
> - What is the **main role** of the transport layer?
> - What is the **difference** between the transport layer and the network layer?
> - What are the functions of **multiplexing** and **demultiplexing**?
> - What are the **fundamental differences** between TCP and UDP?
> - What fields make up the **TCP segment structure**?
> - How is **Reliable Data Transfer (RDT)** implemented in principle?
> - What is the difference between **GBN (Go-Back-N)** and **SR (Selective Repeat)** protocols?
> - What do **flow control** and **congestion control** in TCP each manage?
> - How do **Slow Start**, **Congestion Avoidance**, and **Fast Recovery** operate?
> - Why was the **QUIC protocol** introduced, and how does it differ from **TCP**?

---

## 4.1 Transport Layer Services and Overview

### Role of the Transport Layer

- Provides **logical communication between processes** running on different hosts
- Operates **above the network layer (IP)**, extending IP’s “**host-to-host delivery**” to “**process-to-process delivery**”
- Works **only at the end systems** — routers do not process transport-layer data

### Operational Concept

- **Sender side**: divides application data into **segments**, adds headers, and passes them to the IP layer
- **Receiver side**: reassembles segments delivered by IP and sends the data to the appropriate process
- Responsible for **reliability, error recovery, and ordering** of data

### Relationship with the Network Layer

| Category | Network Layer (IP) | Transport Layer (TCP/UDP) |
| --- | --- | --- |
| Communication Unit | Host ↔ Host | Process ↔ Process |
| Operation | Present in all routers | Operates only in end systems |
| Service | Unreliable (best-effort) | TCP: Reliable / UDP: Unreliable |
- Transport-layer services are **limited by the network layer’s capabilities** (no delay or bandwidth guarantees)
- TCP provides reliability over unreliable IP through **error detection and retransmission**

### Main Protocols

| Protocol | Characteristics | Typical Use Cases |
| --- | --- | --- |
| **TCP** | Reliable, connection-oriented, flow/congestion control | HTTP, FTP, SMTP |
| **UDP** | Unreliable, connectionless, low delay | Streaming, gaming, DNS |

### IP Service Model

- **Best-effort delivery**
    
    → No guarantees of **delivery, order, or integrity**
    
- TCP builds **Reliable Data Transfer (RDT)** on top of this best-effort service

---

## 4.2 Multiplexing & Demultiplexing

### Concept

- **Multiplexing**: The process of gathering data from multiple application processes and sending them through the network.
- **Demultiplexing**: The process of delivering received segments to the **correct socket (process)**.
- In other words, it extends **“host-to-host delivery”** into **“process-to-process delivery.”**

### Basic Operations of the Transport Layer

1. **On the receiving side**
    - Receives a segment from the network layer
    - Checks the segment’s **header fields (e.g., port numbers)**
    - Delivers data to the appropriate socket (**demultiplexing**)
2. **On the sending side**
    - Collects data from multiple sockets
    - Adds headers containing **source and destination port numbers**
    - Encapsulates the data into segments and passes them to the network layer (**multiplexing**)

### UDP Multiplexing / Demultiplexing

- A UDP socket is identified by a **2-tuple: (Destination IP, Destination Port)**.
- Segments with the same destination IP and port are delivered to the **same socket**.
- The **source port number** serves as a return address for replies.

> Example: In a DNS query (UDP port 53), the client opens a temporary port,
> 
> 
> and the server responds to **destination port 53** on the client’s request.
> 

### TCP Multiplexing / Demultiplexing

- A TCP connection is identified by a **4-tuple: (Source IP, Source Port, Destination IP, Destination Port)**.
- This means multiple clients can connect to the **same server port (e.g., 80)** simultaneously,
    
    since each connection has a unique 4-tuple.
    

> Example: A web server listens on port 80,
> 
> 
> but each client connection uses a different combination of source IP and port,
> 
> allowing multiple sessions to coexist concurrently.
> 

### Example of TCP Connection Establishment

1. The client creates a TCP socket and sends a **connection request (SYN)**.
2. The server accepts the request through a **well-known port (e.g., 80)**.
3. Once established, the server creates a new **connection socket**
    - Identifier: (Client IP, Client Port, Server IP, Server Port)
4. Subsequent data is delivered through that connection socket (**demultiplexing**).

### Multiple Connections in a Web Server

- Even if multiple clients connect to the **same server port (80)**,
    
    each connection is treated separately because the **source IP/port pairs differ**.
    
- High-performance servers handle multiple connections using **threads** or **asynchronous event loops** for efficiency.

---

## 4.3 Connectionless Transport: UDP (User Datagram Protocol)

### Concept

- **UDP** provides the **simplest form of transport-layer service**.
- Adds only minimal functionality on top of IP — mainly **multiplexing/demultiplexing** and **basic error checking**.
- **Connectionless:** No handshake before transmission, no connection state maintained.

### Operation

1. The application process generates a message.
2. A segment is created with **source and destination port numbers** added.
3. The segment is passed to the IP layer, **encapsulated into a datagram**, and sent.
4. The receiver delivers the segment to the correct **socket** based on the destination port number.

> UDP follows a “send and forget” model —
> 
> 
> there is no connection setup or congestion control, resulting in **minimal delay**.
> 

### Advantages of UDP

- **Fast transmission:** No 3-way handshake before sending.
- **Low latency:** Data is sent immediately to the IP layer.
- **Small header overhead:** 8 bytes (compared to TCP’s 20 bytes).
- **Stateless:** The server can handle many clients simultaneously.
- **Application-level control:** Applications can implement their own reliability or congestion control if needed.

> Examples: DNS, streaming, online gaming, VoIP, QUIC
> 

### Disadvantages of UDP

- **No congestion control** → risk of network overload.
- **No reliability** → no guarantee of delivery or order.
- **No error recovery** → checksum detects errors but does not fix them.

> If many UDP senders transmit at once, TCP traffic may be suppressed,
> 
> 
> leading to **fairness issues** in bandwidth sharing.
> 

### UDP Segment Structure

| **Source Port #** | **Destination Port #** |
| --- | --- |
| **Length** | **Checksum** |
| **Application Data (Message)** |  |

> Total UDP header size: 8 bytes (fixed)
> 
> 
> Much simpler than TCP, containing only minimal control information.
> 

### UDP Checksum

- The sender adds all 16-bit words and takes the **one’s complement**.
- The receiver repeats the calculation:
    - If the result is `1111111111111111`, the segment is valid.
    - If any `0` appears, an error is detected.
- Errors are **detected but not corrected** — retransmission is left to higher layers.

### Extending UDP Reliability

- UDP itself is unreliable, but **applications can implement reliability on top of it.**
    
    → Example: Google’s **QUIC**
    
    - Runs **over UDP**
    - Implements its own **retransmission, congestion control, and encryption**
    - Serves as the transport foundation for **HTTP/3**

---

## 4.4 Principles of Reliable Data Transfer (RDT)

### Concept

- **Reliable Data Transfer (RDT)** ensures that **data is delivered accurately, in order, and without loss or corruption**
- Since real networks (IP) are unreliable, the transport layer (e.g., TCP) must implement reliability itself
- The same concept applies to the **link layer** and **application layer** as well

### Core Goals

- **Data Integrity:** Deliver data without bit errors
- **Loss Recovery:** Detect and retransmit lost packets
- **In-order Delivery:** Ensure packets arrive in the same order they were sent

### Key Components

| Component | Role |
| --- | --- |
| **Checksum** | Detects bit errors |
| **Sequence Number** | Manages order and duplication |
| **ACK (Acknowledgment)** | Confirms correct reception |
| **NAK (Negative Acknowledgment)** | Reports detected errors |
| **Timer** | Detects loss and triggers retransmission |
| **Window** | Controls pipelining (GBN, SR) |

### rdt1.0 — Perfectly Reliable Channel

- The underlying channel is fully reliable → **no errors or loss**
- Sender: `rdt_send(data)` → creates and sends a packet
- Receiver: `rdt_rcv(packet)` → delivers data to the upper layer
- **No feedback required**, single state machine

### rdt2.0 — Channel with Bit Errors

- The channel may **corrupt bits** during transmission
- Introduces **ARQ (Automatic Repeat reQuest)** concepts
    - Error detection (checksum)
    - Feedback (ACK/NAK)
    - Retransmission on errors
- **Stop-and-Wait protocol:** Send one packet → wait for ACK/NAK → send the next

> Problem: If an ACK/NAK is corrupted, the sender cannot tell the receiver’s state → may retransmit duplicates
> 

### rdt2.1 / rdt2.2 — Handling Damaged ACK/NAK

- Adds a **sequence number** to each packet
- Receiver can distinguish **duplicate packets**
- **rdt2.1:** Uses both ACK and NAK
- **rdt2.2:** Removes NAK, uses **duplicate ACKs** instead
    
    → Receiving the same ACK twice triggers a retransmission
    

### rdt3.0 — Channel with Loss

- Packets or ACKs may be **lost**
- Sender uses a **timer**
    - If no ACK arrives within a timeout, retransmit the packet
    - Implements a **Stop-and-Wait + Timeout** mechanism
- Sequence numbers prevent duplicate confusion
- Also known as the **Alternating Bit Protocol (ABP)**

### Pipelined Reliable Data Transfer

- Stop-and-Wait is inefficient → introduces **pipelining**
- Allows multiple packets to be sent before receiving ACKs → improves throughput
- Requires extended sequence numbers, buffering, and new retransmission policies

| Problem | Solution |
| --- | --- |
| Order management | Extend sequence number space |
| Loss recovery | Implement retransmission rules |
| Buffering | Use sender and receiver buffers |

### Go-Back-N (GBN)

- **Cumulative ACK–based** pipelined protocol
- Window size = N → up to **N unacknowledged packets** can be in transit
- If a loss occurs → retransmit **all packets after the lost one**
- Receiver discards **out-of-order** packets
- Simple but has **high retransmission overhead**

### Selective Repeat (SR)

- **Selective retransmission:** only the lost packets are resent
- Each packet has its own **ACK and timer**
- Receiver **buffers out-of-order** packets and reorders them for delivery
- More efficient but more complex to implement

| Aspect | GBN | SR |
| --- | --- | --- |
| Retransmission unit | All packets after a loss | Only the lost packets |
| Receiver buffering | No | Yes |
| Complexity | Low | High |
| Efficiency | Low (many redundant transmissions) | High (minimal retransmission) |

---

## 4.5 Connection-Oriented Transport: TCP (Transmission Control Protocol)

### Characteristics of TCP

- **Connection-Oriented:** The sender and receiver establish a connection using a **3-way handshake** and terminate it with a **4-way handshake**
- **Reliable Transfer:** Ensures accurate delivery by handling **loss, duplication, and out-of-order errors**
- **Full-Duplex Communication:** Both sides can send and receive simultaneously, maintaining **two independent data streams**
- **Point-to-Point Communication:** Each connection supports **1:1 communication only**, not multicast or broadcast
- **Flow Control:** Adjusts sending rate using the **receive window (rwnd)** to prevent receiver buffer overflow
- **Congestion Control:** Reduces the sending rate during congestion and **gradually increases** it as the network stabilizes
- **Byte Stream Service:** Treats data as a **continuous, boundaryless stream of bytes** instead of discrete messages
- **In-order Delivery:** Buffers and reassembles out-of-order segments to ensure data is delivered **in sequence** to the application

### TCP Connection and Operation

1. **Connection Establishment (3-Way Handshake)**
    - SYN → SYN+ACK → ACK in three steps
    - `SYN` indicates a request to **synchronize sequence numbers**
    - The initial sequence numbers (ISNs) are exchanged and the connection is established
    
    | Step | Sender Action | Receiver Action | Description |
    | --- | --- | --- | --- |
    | ① | Send `SYN` (SYN=1, Seq=x) |  | Start connection request |
    | ② |  | Send `SYN+ACK` (SYN=1, ACK=x+1, Seq=y) | Acknowledge connection |
    | ③ | Send `ACK` (ACK=y+1, SYN=0) |  | Connection established |
2. **Data Transmission**
    - Data from the application is passed to TCP as a **stream**
    - TCP divides the stream into **segments** and sends them to the IP layer
    - The receiver stores the segments in a buffer and passes them to the application
    
    > Each socket maintains its own send buffer and receive buffer
    > 
3. **Connection Termination**
    
    
    | Step | Sender (Client) | Receiver (Server) | Description |
    | --- | --- | --- | --- |
    | ① | **FIN=1** |  | Client → "No more data to send" |
    | ② |  | **ACK=1** | Server → "Acknowledged" |
    | ③ |  | **FIN=1** | Server → "I have no more data either" |
    | ④ | **ACK=1** |  | Client → "Acknowledged, connection closed" |

### TCP Segment Structure

| **Field** | **Size (Byte)** | **Description** |
| --- | --- | --- |
| **Source Port #** | 2 | Identifies the sending process |
| **Destination Port #** | 2 | Identifies the receiving process |
| **Sequence Number** | 4 | Byte number of the first data byte in the segment |
| **Acknowledgment Number** | 4 | Next byte number expected by the receiver |
| **Header Length** | 4 bits | Specifies header length |
| **Flags (6 bits)** | - | Control bits (SYN, ACK, FIN, RST, PSH, URG) |
| **Receive Window** | 2 | Receiver buffer size (for flow control) |
| **Checksum** | 2 | Error detection |
| **Urgent Pointer** | 2 | Marks the end of urgent data |
| **Options** | Variable | Settings such as MSS and window scaling |
| **Data** | Variable | Application data payload |
- `Source Port Number`: identifies the sending process
- `Destination Port Number`: identifies the receiving process
- `Checksum`: detects transmission errors
- `Sequence Number` and `Acknowledgment Number`: manage ordering and reliability
- `Receive Window`: used for flow control
- `Header Length`: specifies the size of the header
- `Options`: optional variable-length field for features like MSS negotiation and window scaling
- `Flag Field (6 bits)`:
    - **ACK:** indicates that the acknowledgment field is valid
    - **RST, SYN, FIN:** used for connection setup and termination
    - **PSH:** instructs the receiver to deliver data to the upper layer immediately
    - **URG:** marks urgent data, with its position indicated by the **Urgent Pointer field**

### Sequence and Acknowledgment Numbers

> TCP treats data as a continuous byte stream, not as structured messages
> 
- **Sequence Number:** First byte number of the segment
- **Acknowledgment Number:** Next expected byte number
- **Cumulative ACK:** Acknowledges all bytes up to a certain number
- Out-of-order segments are **buffered and reordered** before delivery

### RTT Estimation and Timeout

- **RTT (Round Trip Time)** measures the time from segment transmission to ACK reception
- TCP uses measured RTTs to estimate an **average RTT**
- It also tracks **deviation** to account for delay variations
- The **Timeout Interval** is set slightly longer than the average RTT to
    
    **avoid unnecessary retransmissions while quickly detecting loss**
    

### Reliable Data Transfer in TCP

> TCP provides a reliable data transfer service over IP’s best-effort delivery
> 
- Ensures data integrity, no duplication, and correct order
1. **Data Transmission:** Application → TCP segment → IP layer
2. **Timeout:** Retransmit segment after timeout expiration
3. **ACK Reception:** Update send buffer and timer based on cumulative ACKs
    - `SendBase`: sequence number of the oldest unacknowledged byte
    - `SendBase - 1`: last in-order byte acknowledged by the receiver

> TCP mainly follows a GBN-style protocol,
> 
> 
> but buffers out-of-order segments and, with **Selective Acknowledgment (SACK)**,
> 
> behaves similarly to **SR (Selective Repeat)**
> 

### Fast Retransmit

- If **three duplicate ACKs** are received for the same data,
    
    TCP retransmits the missing segment **immediately**, without waiting for a timeout
    
- Detects losses quickly and minimizes transmission delay

### Flow Control

- Prevents receiver buffer overflow
- Receiver advertises available buffer space using the **receive window (rwnd)**
- Sender ensures `unacknowledged data ≤ rwnd`
- When `rwnd = 0`, the sender periodically transmits a **1-byte probe** to check availability

### SYN Flood Attack and Defense

- **Attack:** The attacker sends many SYN requests but never replies with ACKs, exhausting server resources
- **Defense (SYN Cookie):** The server avoids storing connection state until the client’s ACK arrives,
    
    using a **hash-based Initial Sequence Number (ISN)** to validate requests and prevent resource exhaustion
    

---

## 4.6 **TCP Congestion Control**

### Concept

- **Congestion** occurs when **too many senders transmit data too quickly**, overwhelming the network.
- When router buffers overflow or link capacity is exceeded, it results in **increased delay, packet loss, and retransmissions**.
- The goal of congestion control is to **adjust the sending rate** to maintain **network stability and efficiency**.

### Causes and Costs of Congestion

### Scenario 1: Two Senders, Infinite Buffer Router

- Two senders share the same link (R bps).
- As each sender increases its sending rate, throughput per sender cannot exceed R/2.
- As rates approach R/2, **delay increases exponentially**; beyond R/2, **delay grows without bound**.

> Even with infinite buffers, congestion increases delay without improving throughput.
> 

### Scenario 2: Finite Buffer Router

- Limited buffer capacity leads to **packet loss**.
- Lost packets are **retransmitted**, increasing total load on the network.

| Situation | Result |
| --- | --- |
| No packet loss | Throughput ≈ sending rate (λ_in) |
| Packet loss + retransmissions | Throughput decreases (bandwidth wasted on retransmissions) |
| Excessive timeouts | Retransmissions occur even for delayed packets → **wasted bandwidth** |

> The more retransmissions occur, the worse congestion becomes, reducing overall network efficiency.
> 

### Scenario 3: Multiple Senders, Multi-hop Path

- Many senders compete at shared routers.
- Bottleneck links become overloaded, causing **some flows’ throughput to approach zero**.
- Lost packets waste bandwidth along the entire path.

> Congestion affects not just a single node but the entire end-to-end path, wasting shared network resources.
> 

### Approaches to Congestion Control

| Type | Description | Example |
| --- | --- | --- |
| **End-to-End Congestion Control** | Network provides no explicit feedback; sender **infers congestion from loss or delay** | TCP |
| **Network-Assisted Congestion Control** | Routers **detect congestion and send feedback** directly to senders | ATM ABR, ECN |

### End-to-End Congestion Control (TCP Approach)

- TCP interprets **packet loss** and **increasing RTT** as signals of congestion.
- When congestion is detected, TCP **reduces its congestion window (cwnd)** to lower the sending rate.
- As the network recovers, the window is **gradually increased** to restore throughput.

> TCP follows a hybrid approach, combining loss-based and delay-based control.
> 

### Network-Assisted Congestion Control

- Routers provide congestion feedback directly to senders.
- Two main feedback methods exist:

| Method | Description |
| --- | --- |
| **Explicit Feedback** | The router sends a **choke packet** or other control message to the sender. |
| **Implicit Feedback** | The router marks packet headers, allowing the receiver to infer congestion and notify the sender (requires an extra RTT). |

> Modern TCP/IP networks support ECN (Explicit Congestion Notification),
> 
> 
> where routers mark packets instead of dropping them, enabling proactive congestion signaling.
> 

---

## 4.7 Principles of Congestion Control

### Concept of Congestion

- **Congestion** occurs when **too many senders transmit data too quickly** for the network to handle.
- This leads to **router buffer overflow → packet loss → retransmissions → increased delay**.
- TCP manages congestion by using a **congestion control mechanism** that adjusts the sending rate dynamically.

### TCP Congestion Control Variables

- **cwnd (Congestion Window):** Controls how much data a sender can have in flight (unacknowledged).
- **rwnd (Receive Window):** Indicates available space in the receiver’s buffer.
- Actual amount of data that can be sent:
    
    `LastByteSent - LastByteAcked ≤ min(cwnd, rwnd)`
    
    → The sender’s transmission rate is limited by the **smaller of cwnd and rwnd**.
    

### Detecting Congestion

1. **Loss Event**
    - Triggered by a timeout or **three duplicate ACKs**.
    - Interpreted as a signal of network congestion.
2. **Self-Clocking**
    - Uses the arrival rate of ACKs as a pacing mechanism.
    - Slow ACKs indicate congestion, while fast ACKs indicate available bandwidth.

### TCP Congestion Control Components

1. **Slow Start**
2. **Congestion Avoidance**
3. **Fast Recovery** *(recommended but optional)*

### 1) Slow Start

- At connection start, **cwnd = 1 MSS**.
- For each received ACK, cwnd **doubles every RTT** (exponential growth).
- Quickly increases the sending rate to probe available bandwidth.

**Exit Conditions:**

- On **loss event** → set `cwnd = 1` and restart slow start.
- When **cwnd ≥ ssthresh** → switch to **congestion avoidance**.
- On **three duplicate ACKs** → enter **fast recovery**.

### 2) Congestion Avoidance

- Activated when **cwnd ≥ ssthresh**.
- Grows **linearly (Additive Increase)** by 1 MSS per RTT.
- Aims to prevent congestion by increasing the rate carefully.

**Exit Conditions:**

- On **timeout** → set `cwnd = 1`, `ssthresh = cwnd / 2`, and return to slow start.
- On **three duplicate ACKs** → switch to fast recovery.

### 3) Fast Recovery

- Triggered after receiving **three duplicate ACKs**.
- Retransmits the missing segment immediately.
- Reduces cwnd to half (`ssthresh = cwnd / 2`) and then
    
    **increases cwnd by 1 MSS per duplicate ACK** received.
    
- Once the lost segment is acknowledged → transition back to **congestion avoidance**.

### AIMD (Additive Increase, Multiplicative Decrease)

- Core principle of TCP congestion control.
- **Additive Increase (AI):** Gradually increases cwnd by 1 MSS per RTT.
- **Multiplicative Decrease (MD):** Halves cwnd when congestion is detected.
- “**Increase cautiously, decrease aggressively**” ensures both efficiency and fairness.

### Comparison of Congestion Control Phases

| Phase | Increase Behavior | Decrease Trigger | cwnd Adjustment | Throughput Change |
| --- | --- | --- | --- | --- |
| **Slow Start** | Exponential | Loss event | Reset to 1 MSS | Rapid growth |
| **Congestion Avoidance** | Linear | Loss event | Halve cwnd | Gradual increase |
| **Fast Recovery** | Linear (after retransmit) | 3 duplicate ACKs | Halve cwnd | Quick recovery after loss |

### TCP CUBIC (Modern Congestion Control)

- Enhanced version of **TCP Reno** (default in Linux).
- Adjusts cwnd using a **cubic function** based on the previous maximum window `Wmax`.
- Quickly approaches `Wmax`, then explores available bandwidth **smoothly around that point**.
- Performs better in **high-bandwidth, high-latency networks**.

### Explicit Congestion Notification (ECN)

- **Routers mark packets** with ECN bits instead of dropping them when congestion is detected.
- The receiver sets the **ECE (Explicit Congestion Echo)** flag in ACKs to notify the sender.
- The sender halves its cwnd and responds with the **CWR (Congestion Window Reduced)** flag to acknowledge the adjustment.
- Enables **congestion signaling without packet loss**.

### Delay-Based Congestion Control (TCP Vegas)

- Detects congestion **based on delay (RTT increase)** rather than packet loss.
- When RTT exceeds the minimum observed RTT (RTTmin), TCP assumes queue buildup.
- Reduces sending rate **before congestion occurs**, improving delay and stability.

### Fairness

- When multiple TCP connections share a bottleneck link, each flow tends to receive an **equal share of bandwidth**.
- Under AIMD, the average throughput for each connection is roughly **R / K** (R = link capacity, K = number of flows).
- However, flows with **shorter RTTs** increase cwnd faster and may get slightly more bandwidth.

> UDP lacks congestion control, so it can consume bandwidth unfairly, affecting TCP flows.
> 

---

## 4.8 Evolution of Transport Layer Functionality

### Overview

- New transport protocols have emerged to **improve connection setup speed** and **stream-handling efficiency** while maintaining TCP’s reliability and congestion control performance.
- The most notable example is **QUIC (Quick UDP Internet Connections)**.

### QUIC (Quick UDP Internet Connections)

- Operates **on top of UDP** but provides **TCP-level reliability and congestion control**.
- Developed by **Google**, now adopted as the **core transport protocol for HTTP/3**.
- Today, a significant portion of global Internet traffic already runs over **QUIC**.

### Key Features of QUIC

### Connection-Oriented and Secure

- QUIC functions as a **connection-oriented protocol** built on top of UDP.
- It combines the **TCP 3-way handshake** and **TLS security handshake** into a **single step**,
    
    → **Greatly reducing connection setup time** (lower RTT).
    
- Connections are managed through a **Connection ID**, allowing the connection to **persist even if the IP address changes**.

### Stream Multiplexing

- A single QUIC connection can carry **multiple independent streams**.
- Each stream provides **reliable delivery** and **independent error recovery**.
- Loss in one stream **does not block** others,
    
    → effectively solving TCP’s **Head-of-Line (HOL) blocking problem**.
    

### Reliable Transfer and Congestion Control

- Provides **ACK-based reliable delivery**, similar to TCP.
- Uses an enhanced **TCP NewReno–style congestion control algorithm**.
- Each stream handles **its own error recovery and retransmission**, ensuring smooth performance under loss.

### Comparison of HTTP Versions

| Feature | **HTTP/1.1** | **HTTP/3 (QUIC-based)** |
| --- | --- | --- |
| **Transport Layer** | TCP | UDP + QUIC |
| **Security Layer** | TLS (separate) | Integrated into QUIC |
| **Stream Structure** | Single stream | Multiple parallel streams |
| **Loss Impact** | Delays entire connection (HOL blocking) | Affects only the impacted stream |
| **Connection Setup Time** | 2 or more RTTs | 1 RTT or less |

### Advantages of QUIC

- **Faster connection setup** (reduced RTT compared to TCP+TLS)
- **Parallel, stream-level transmission**
- **Built-in security layer (TLS 1.3 integrated)**
- **Loss isolation** to minimize latency
- **More flexibility in implementation**, since it runs in user space rather than the OS kernel
